<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<!-- <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" /> -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<!-- <link rel="stylesheet" href="css/jemdoc.css" type="text/css" /> -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
<link rel='stylesheet' href="my_style.css">
<title>Yue's Homepage</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-124162585-1");
    pageTracker._trackPageview();
} catch(err) {}</script>


<!--TODO THIS IS MY SCRIPT -->
<script>
function FadeIn(q) {
q.volume=0.05;
FadeInLoop(q);
}
function FadeInLoop(q){
  var end_vol=50;
  var vol = q.volume*100;
  if ( vol+1 < end_vol )
    {
        console.log(vol);
        q.volume = ((vol+1) / 100);
        setInterval(function() { FadeInLoop(q) }, 1200);
    }
}
</script>





<div class="sidenav">
  <div>
    <img class="clip-svg" src="data/avatar.jpg" width="180">
  </div>

  <div class="menu-title">INTRO</div>
  <div class="menu-item"><a href="#main_anchor">Home</a></div>
  <div class="menu-item"><a href="data/cv.pdf" target="_blank">Resume <span class='fas fa-external-link-alt fa-1x'></span> </a></div>
  <div class="menu-item"><a href="#publications_anchor">Publications</a></div>

  <div class="menu-title">TECH</div>
  <div class="menu-item"><a href="#collecting_anchor" onclick="collapseFunction('collecting_anchor');">Collecting</a></div>
  <div class="menu-item"><a href="iros2018-slam-papers" target="_blank">IROS2018SLAM <span class='fas fa-external-link-alt fa-1x'></span> </a></div>

  <div class="menu-title">MISC</div>
  <div class="menu-item"><a href="https://www.bilibili.com/video/av35787189" target="_blank">我们自35班 <span class='fas fa-external-link-alt fa-1x'></span> </a></div>
  <div class="menu-item"><a href="#soccer_anchor" onclick="collapseFunction('soccer_anchor');">Soccer</a></div>
  <div class="menu-item"><a href="#running_anchor" onclick="collapseFunction('running_anchor');">Running</a></div>

  <div class="bottom-logos">
    <p></p>
    <a class="fa-a" href="https://www.facebook.com/yue.meng.75" target="_blank">
      <span class="fab fa-facebook fa-2x"></span>
    </a>
    <a class="fa-a" href="https://github.com/mengyuest" target="_blank">
      <span class="fab fa-github fa-2x"></span>
    </a>
    <a class="fa-a" href="https://www.linkedin.com/in/yuemeng95" target="_blank">
      <span class="fab fa-linkedin fa-2x"></span>
    </a>
    <a class="fa-a" href="https://www.instagram.com/misha_ucsd" target="_blank">
      <span class="fab fa-instagram fa-2x"></span>
    </a>
    <p></p>
    </div>

</div>
<div class="main" id="main_anchor">
  <h1>Meng, Yue (孟岳)</h1>
  <!-- <hr> </hr> -->

  <p>I am a 4<sup>th</sup> year PhD student at <a href="https://www.mit.edu/">MIT</a> <a href="https://aeroastro.mit.edu">AeroAstro</a>, working in <a href="https://aeroastro.mit.edu/realm"><b>REALM lab</b></a>. <br />
    My research topic is <i>using machine learning techniques for safe and robust robot control</i>. <br />
    Before that, I was an AI Resident at <a href="https://mitibmwatsonailab.mit.edu/?lnk=research">IBM Thomas J. Waston Research Center</a>.<br />
    I received an M.S. degree in <a href="https://www.ece.ucsd.edu/">ECE</a> at <a href="https://ucsd.edu/">UC San Diego</a> and worked in <a href="https://existentialrobotics.org/">ERL</a> and <a href="https://wcsng.ucsd.edu">WCSNG</a>, <br />
    and a B.S. degree in the <a href="https://tsinghua.edu.kg/publish/au/index.html">Department of Automation</a> from <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>.</p>

  <table >
  <tr class="row">
    <td class="logo-col">
      <a href="https://www.mit.edu/" target="_blank" title="MIT">
      <img class="logo-figure" src="data/logos/MIT-logo.png" alt="MIT"></a>
    </td>
    <td class="logo-col">
      <a href="https://ucsd.edu/" target="_blank" title="UCSD">
      <img class="logo-figure" src="data/logos/UCSD-logo.png" alt="UCSD"></a>
    </td>
    <td class="logo-col">
      <a href="https://www.tsinghua.edu.cn/en/" target="_blank" title="Tsinghua">
      <img class="logo-figure" src="data/logos/THU-logo.png" alt="Tsinghua"></a>
    </td>
    <td class="logo-col">
      <a href="http://www.tsinghuaveterans.com/" target="_blank" title="Tsinghua Veterans Soccer">
      <img class="logo-figure" src="data/logos/tsinghua-veteran-logo.png" alt="Tsinghua Veterans Soccer"></a>
    </td>
    <td class="logo-col">
      <a href="https://sites.google.com/view/sdred/" target="_blank" title="San Diego Red Army Soccer">
      <img class="logo-figure" src="data/logos/san-diego-red-army.png" alt="San Diego Red Army Soccer"></a>
    </td>
    <td class="logo-col">
      <a href="https://sites.google.com/view/nccsfweb/teams/calblue" target="_blank" title="Calblue Soccer Team">
      <img class="logo-figure" src="data/logos/calblue-logo.jpg" alt="Calblue Soccer Team"></a>
    </td>
  </tr>
</table>
<table>
  <tr>
    <td class="logo-col1">
      <a href="https://www.microsoft.com/en-us/research/" target="_blank" title="Microsoft Research">
        <img class="logo-figure1" src="data/logos/microsoft-logo.jpg" alt="Microsoft Research"></a>
    </td>
    <!-- <td class="logo-col1">
      <a href="https://aeroastro.mit.edu/" target="_blank" title="MIT AeroAstro">
        <img class="logo-figure1" src="data/logos/aero-astro-logo-long.png" alt="MIT AeroAstro"></a>
    </td> -->
    <td class="logo-col1">
      <a href="https://mitibmwatsonailab.mit.edu/" target="_blank" title="MIT-IBM Watson AI Lab">
        <img class="logo-figure1" src="data/logos/mit-ibm-ai-lab-logo.png" alt="MIT-IBM Watson AI Lab"></a>
    </td>
    <td class="logo-col1">
      <a href="https://www.google.com/" target="_blank" title="Google">
        <img class="logo-figure1" src="data/logos/google-logo.jpg" alt="Google"></a>
    </td>
  </tr>

    <tr>
    <td class="logo-col1">
      <a href="https://usa.honda-ri.com/" target="_blank" title="Honda Research">
        <img class="logo-figure1" src="data/logos/hri-us-logo-2018.png" alt="Honda Research"></a>
    </td>
    <td class="logo-col1">
      <a href="https://www.tusimple.com/" target="_blank" title="TuSimple">
        <img class="logo-figure1" src="data/logos/TuSimple-Logo.jpg" alt="TuSimple"></a>
    </td>
    <td class="logo-col1">
      <a href="https://smart.mit.edu/" target="_blank" title="Singapore-MIT Alliance">
        <img class="logo-figure1" src="data/logos/smart-logo.png" alt="Singapore-MIT Alliance"></a>
    </td>
  </tr>
  </table>


  <h2>Contact</h2>
<ul><li><p>Email: mengyuethu@gmail.com</p></li></ul>
<ul><li><p>Email: mengyue@mit.edu</p></li></ul>

<h2 id="publications_anchor">Publications</h2>
<table>
  <tr>
    <td class="pub-figure"> <img class="pub-img" src="data/l4dc2023.gif"/> </td>
    <td class="pub-text">
    <h3>Hybrid Systems Neural Control with Region-of-Attraction Planner</h3>
    <p><b>Yue Meng</b>, Chuchu Fan<br />
    <i>5th Annual Learning for Dynamics & Control Conference (L4DC), 2023</i><br />
    [<a href="https://arxiv.org/pdf/2303.10327.pdf">arXiv</a>] [<a href="https://mit-realm.github.io/hybrid-clf">page</a>]
    <p>In this work, we propose a neural network (NN)-based method to control hybrid systems. Upon mode switching, we propose a differentiable planner to ensure the states after switching can land in next mode's RoA, hence stabilizing the hybrid system. With low running time, our controller achieves a higher stability/success rate over MPC, RL, common Lyapunov methods (CLF), linear quadratic regulator (LQR), quadratic programming (QP) and Hamilton-Jacobian-based methods (HJB).
    </p>
    </td>
  </tr>
  <tr>
    <td class="pub-figure"> <img class="pub-img" src="data/icra2023.gif"/> </td>
    <td class="pub-text">
    <h3>Density Planner: Minimizing Collision Risk in Motion Planning with Dynamic Obstacles using Density-based Reachability</h3>
    <p>Laura Lützow, <b>Yue Meng</b>, Andres Chavez Armijos, Chuchu Fan<br />
    <i>IEEE Int. Conf. on Robotics and Automation (ICRA), 2023</i><br />
    [<a href="https://arxiv.org/pdf/2210.02131.pdf">arXiv</a>] [<a href="https://youtu.be/jdwnddtrBnI">video</a>] [<a href="https://github.com/MIT-REALM/density_planner">code</a>]
    <p>We propose a density-based method which uses a neural network and the Liouville equation to learn the density evolution for a system with an uncertain initial state. We conduct motion planning experiments on simulated environments and environments generated from real-world data and outperform baseline methods such as model predictive control and nonlinear programming. While our method requires offline planning, the online run speed is 100times faster compared to model predictive control. 
    </p>
    </td>
  </tr>

  <tr>
    <td class="pub-figure"> <img class="pub-img" src="data/nfm2022.png"/> </td>
    <td class="pub-text">
    <h3>Density of Reachable States and How to Use it for Safe Autonomous Motion Planning</h3>
    <p><b>Yue Meng</b>, Zeng Qiu, Md Tawhid Bin Waez, Chuchu Fan<br />
    <i>NASA Formal Methods Symposium (NFM), 2022</i><br />
    [<a href="https://drive.google.com/file/d/1Q-cU3MRY-nd2wydaSzwJ76cMy9DVIjQa/view?usp=sharing">pdf</a>]
    <p>
     Recent work provides a data-driven approach to compute the density distribution of autonomous systems’ forward reachable states online. In this paper, we study the use of such approach in combination with model predictive control for verifiable safe path planning under uncertainties. We design two challenging scenarios (autonomous driving and hovercraft control) for safe motion planning in environments with obstacles under system uncertainties. By leveraging the estimated risk, our algorithm achieves the highest success rate in goal reaching when enforcing the safety rate above 0.99.</p>
    </td>
  </tr>

  <tr>
    <td class="pub-figure"> <img class="pub-img" src="data/corl2021.png"/> </td>
    <td class="pub-text">
    <h3>Learning Density Distribution of Reachable States for Autonomous Systems</h3>
    <p><b>Yue Meng</b>, Dawei Sun, Zeng Qiu, Md Tawhid Bin Waez, Chuchu Fan<br />
    <i>Conference of Robotics and Learning (CoRL), 2021</i><br />
    [<a href="https://arxiv.org/pdf/2109.06728.pdf">arXiv</a>][<a href="https://github.com/mengyuest/nn_reachable_density/">code</a>][<a href="https://youtu.be/GiL7pRFgr0s">seminar</a>]
    <p>In this work, we propose a data-driven method to compute the density distribution of reachable states for nonlinear systems. Our approach learns system dynamics and the state density jointly from trajectory data, guided by the fact that the state density evolution follows the Liouville partial differential equation. We show that our learned solution can produce a much more accurate estimate on density distribution, and can quantify risks less conservatively and flexibly compared with worst-case analysis.</p>
    </td>
  </tr>

  <tr>
    <!-- <td class="pub-figure"> <img class="pub-img" src="data/preprint.png"/> </td> -->
    <td class="pub-figure"> <img class="pub-img" src="data/iros2021.gif"/> </td>
    <td class="pub-text">
      <h3>Reactive and Safe Road User Simulations using Neural Barrier Certificates</h3>
      <p><b>Yue Meng</b>, Zengyi Qin, Chuchu Fan<br />
      <i>IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS), 2021.</i> <br />
      [<a href="https://arxiv.org/pdf/2109.06689.pdf">arXiv</a>][<a href="http://realm.mit.edu/reactive-agent-models/">page</a>][<a href="https://github.com/mengyuest/reactive_cbf/">code</a>][<a href="https://youtu.be/GiL7pRFgr0s">seminar</a>]
      <p>We proposed a reactive agent model which can ensure safety by learning high-level decisions from expert data and a low level decentralized controller guided by the jointly learned decentralized barrier certificates. Empirical results show that our approach can achieve a significant improvement in safety while being similar to human behaviors.</p>
    </td>
  </tr>

  <tr>
    <td class="pub-figure"> <img class="pub-img" src="data/iclr2021.gif"/> </td>
    <td class="pub-text">
      <h3>AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition</h3>
      <p><b>Yue Meng</b>, Rameswar Panda, Chung-Ching Lin, Prasanna Sattigeri, Leonid Karlinsky, Kate Saenko, Aude Oliva, Rogerio Feris<br />
      <i>Int. Conf. on Learning Representations (ICLR), 2021.</i><br />
    [<a href="https://arxiv.org/pdf/2102.05775.pdf">arXiv</a>][<a href="https://mengyuest.github.io/AdaFuse/">page</a>][<a href="https://github.com/mengyuest/AdaFuse">code</a>]</p> 
      <p>This paper introduces an adaptive temporal fusion, AdaFuse, that dynamically fuses channels for strong temporal modelling. Extensive experiments on SomethingV1\&V2, Jester and Mini-Kinetics show AdaFuse achieves 40\% computation savings with comparable accuracy to state-of-the-art methods</p>
    </td>
  </tr>

  <tr>
    <td class="pub-figure"> <img class="pub-img" src="data/eccv2020.gif"/> </td>
    <td class="pub-text">
      <h3>AR-Net: Adaptive Frame Resolution for Efficient Action Recognition</h3>
      <p><b>Yue Meng</b>, Chung-Ching Lin, Rameswar Panda, Prasanna Sattigeri, Leonid Karlinsky, Aude Oliva, Kate Saenko, Rogerio Feris<br />
      <i>European Conf. on Computer Vision (ECCV), 2020.</i><br />
    [<a href="https://arxiv.org/pdf/2007.15796.pdf">arXiv</a>][<a href="https://mengyuest.github.io/AR-Net">page</a>][<a href="https://github.com/mengyuest/AR-Net">code</a>]</p>  
    <p>This paper proposes a novel approach, AR-Net (Adaptive  Resolution  Network),  that  selects  on-the-fly the optimal resolution for each frame conditioned on the input for efficient action recognition in long untrimmed videos. Extensive experiments on several action recognition datasets well demonstrate the efficacy of our method over state-of-the-art.</p>
    </td>
  </tr>

<tr>
  <td class="pub-figure"> <img class="pub-img" src="data/icra2020_after.gif"/> </td>
  <td class="pub-text">
    <h3>Learning 3D-aware Egocentric Spatial-Temporal Interaction via Graph Convolutional Networks</h3>
    <p>Chengxi Li, <b>Yue Meng</b>, Stanley H. Chan and Yi-Ting Chen<br />
    <i>IEEE Int. Conf. on Robotics and Automation (ICRA), 2020.</i><br />
    [<a href="https://arxiv.org/pdf/1909.09272.pdf">arXiv</a>][<a href="https://sites.google.com/site/yitingchen0524/research/driver-centric-risk-assessment/">page</a>]</p>
    <p>This paper proposes a 3D-aware egocentric spatial-temporalinteraction framework for automated   driving applications. Graph convolution networks (GCN)  is  devised  for  interaction modeling. Extensive   experiments   are   conducted using  Honda  Research  Institute  Driving  Dataset.</p>
  </td>
</tr>
  
<tr>
  <td class="pub-figure"> <img class="pub-img" src="data/iros2019.gif"/> </td>
  <td class="pub-text">
    <h3>Localization and Mapping using Instance-specific Mesh Models</h3>
    <p>Qiaojun Feng, <b>Yue Meng</b>, Mo Shan and Nikolay Atanasov<br />
    <i>IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS), 2019.</i> <br />
    [<a href=" https://natanaso.github.io/ref/Feng_DeformableMeshModel_IROS19.pdf">pdf</a>]</p>
    <p>This paper focuses on building semantic maps, containing object poses and shapes, using a monocular camera. Our
    contribution is an instance-specific mesh model of object shape
    that can be optimized online based on semantic information extracted from camera images.</p>
    </td>
</tr>

<tr>
  <td class="pub-figure"> <img class="pub-img" src="data/signet.gif"/> </td>
  <td class="pub-text">
    <h3>SIGNet: Semantic Instance Aided Unsupervised 3D Geometry Perception</h3>
    <p><b>Yue Meng</b>, Aman Raj, Samuel Sunarjo, Rui Guo, Tara Javidi, Gaurav Bansal, Dinesh Bharadia<br />
    <i>IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2019.</i> <br />
    [<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Meng_SIGNet_Semantic_Instance_Aided_Unsupervised_3D_Geometry_Perception_CVPR_2019_paper.pdf">pdf</a>][<a href="https://mengyuest.github.io/SIGNet/">page</a>][<a href="https://github.com/mengyuest/SIGNet">code</a>]</p>
    <p>This paper introduces SIGNet, a novel framework that provides robust geometry perception without requiring geometrically informative labels. SIGNet is shown to improve upon the state of art unsupervised learning for geometry perception by 30%</p>
  </td>
</tr>

<tr>
  <td class="pub-figure"> <img class="pub-img" src="data/rss2018workshop-1.png"/> </td>
  <td class="pub-text">
    <h3>Dense Spatial Segmentation from Sparse Semantic Information</h3>
    <p>Qiaojun Feng, <b>Yue Meng</b> and Nikolay Atanasov<br />
    <i>Workshop at Robotics: Science and Systems (RSS), 2018.</i> <br />
    [<a href="https://drive.google.com/file/d/1b1C4SMfS0aPwHM7mT4TSl59rD6pnD6gY/view">pdf</a>]</p>
    <p>This paper develops an environment representation that affords reasoning about the occupancy of space, necessary for safe navigation, and about the identity of objects, necessary for complex task interpretation.</p>
  </td>
</tr>

<tr>
  <td class="pub-figure"> <img class="pub-img" src="data/cosim.gif"/> </td>
  <td class="pub-text">
    <h3>Cooperative Driving Strategies for Nonsignalized Intersections</h3>
    <p><b>Yue Meng</b>, Li Li, Fei-Yue Wang, Keqiang Li and Zhiheng Li<br />
    <i>IEEE Transactions on Vehicular Technology (TVT), 2017.</i> <br />
    [<a href="https://www.researchgate.net/profile/Li_Li240/publication/321640653_Analysis_of_Cooperative_Driving_Strategies_for_Non-Signalized_Intersections/links/5a2a88e245851552ae77e917/Analysis-of-Cooperative-Driving-Strategies-for-Non-Signalized-Intersections.pdf">pdf</a>]</p>
    <p>We study the difference between two major strategies of cooperative driving at intersections: the “ad hoc negotiation based” strategy and the "planning based" strategy. We carry out a series of simulations under different traffic scenarios for comparison. Results indicate the performance of a strategy mainly depends on the passing order of vehicles that it finds.</p>
  </td>
</tr>

</table>

<!-- <div>
  <span class="pub-figure"> <img class="pub-img" src="data/signet.gif"/> </span>
  <span class="pub-text"></span>
</div> -->



<h2>Links</h2>
  <ul>
  <li><p><a href="https://existentialrobotics.org">Existential Robotics Laboratory</a></p>
  </li>
  <li><p><a href="https://wcsng.ucsd.edu">Wireless Communication Systems and Networking Group</a></p>
  </li>
  <li><p><a href="https://www.bilibili.com/video/av35787189">自35班毕业纪念视频</a></p>
  </li>
  <li><p><a href="http://www.tsinghuaveterans.com/">Tsinghua Veteran Soccer Team</a></p>
  </li>
  <li><p><a href="https://sites.google.com/view/nccsfweb/teams/tsinghua-veterans-bay-area">Tsinghua Veteran Bay Area Soccer Team</a></p>
  </li>
  <li><p><a href="https://sites.google.com/view/nccsfweb/teams/calblue">CalBlue Soccer Team</a></p>
  </li>
  <li><p><a href="https://sites.google.com/view/sdred/">San Diego Red Army Soccer Team</a></p>
  </li>
  </ul>

<h2 id="collecting_anchor" class="collapsible">Collecting (click to see more)</h2>
<div class="content">
  <h3>Routine</h3>
  <ul>
  <li><p><a href="https://arxiv.org/list/cs.CV/recent">arXiv: Computer Vision and Pattern Recognition</a></p>
  </li>
  <li><p><a href="http://www.arxiv-sanity.com/">arXiv Sanity</a></p>
  </li>
  <li><p><a href="https://assert.pub/">Top 10 arXiv papers Today</a></p>
  </li>
  </ul>
  <h3>Procastination</h3>
  <ul>
  <li><p><a href="https://www.bilibili.com/video/av3584431/">央视纪录片《高考》</a></p>
  </li>
  <li><p><a href="https://aideadlin.es/?sub=RO,CV,ML">AI Conference Deadlines</a></p>
  </li>
  <li><p><a href="https://www.cmu.edu/randyslecture">Randy Pausch's Last Lecture</a></p>
  </li>
  <li><p><a href="https://www.youtube.com/watch?v=a1zDuOPkMSw">You and Your Research</a></p>
  </li>
  </ul>
  <h3>Ph.D.</h3>
  <ul>
  <li><p><a href="https://zhuanlan.zhihu.com/p/29636455">北美博士必读清单</a></p>
  </li>
  <li><p><a href="https://www.zhihu.com/question/28920341">大牛写的非技术类作品</a></p>
  </li>
  <li><p><a href="http://faculty.neu.edu.cn/cc/zhangyf/papers/CraftingFuture.pdf">Crafting Your Research Future</a></p>
  </li>
  <li><p><a href="https://www.cs.unc.edu/~azuma/hitch4.html">CS Graduate Survival Guide</a></p>
  </li>
  <li><p><a href="http://3dvision.princeton.edu/courses/COS598/2014sp/slides/lecture21_how2research.pdf">Doing research in Computer Vision</a></p>
  </li>
  </ul>
  <h3>Robotics</h3>
  <ul>
  <li><p><a href="https://github.com/kanster/awesome-slam">Awesome SLAM</a></p>
  </li>
  <li><p><a href="https://arxiv.org/pdf/1606.05830.pdf">Past, Present and Future of SLAM</a></p>
  </li>
  <li><p><a href="http://ais.informatik.uni-freiburg.de/teaching/ws11/robotics2/pdfs/rob2-13-frontends.pdf">SLAM Front-Ends</a></p>
  </li>
  <li><p><a href="http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Triggs00.pdf">Bundle Adjustment: A Modern Synthesis</a></p>
  </li>
  <li><p><a href="http://cs.brown.edu/research/ai/pomdp/tutorial/">POMDP</a></p>
  </li>
  </ul>
  <h3>Technician</h3>
  <ul>
  <li><p><a href="http://www.docs.is.ed.ac.uk/skills/documents/3722/3722-2014.pdf">LaTeX for Beginners</a></p>
  </li>
  <li><p><a href="https://github.com/onqtam/awesome-cmake">Awesome CMake</a></p>
  </li>
  <li><p><a href="https://cgold.readthedocs.io/en/latest/">CGold: The Hitchhiker's Guide to the CMake</a></p>
  </li>
  </ul>
  <h3>Blogs</h3>
  <ul>
  <li><p><a href="http://www.computervisionblog.com/">Tombone's Computer Vision Blog</a></p>
  </li>
  <li><p><a href="http://www.pgbovine.net/writings.htm">Philip Guo</a></p>
  </li>
  <li><p><a href="https://www.kennethreitz.org/">Kenneth Reitz</a></p>
  </li>
  </ul>
</div>

  <h2 id="soccer_anchor" class="collapsible">Soccer (click to see more)</h2>
  <div class="content">
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-000.jpg" alt="soccer-000" width="500px" />&nbsp;</td>
  <td><p>Champion of Haidian District Soccer League, 2011</p></td></tr>
  <tr>
    <td><img class="misc-img" src="data/soccer-00.jpg" alt="soccer-00" width="500px" />&nbsp;</td>
    <td><p>High School Class Soccer Team, 2012</p></td>
  </tr>
  <tr><td>
  <img class="misc-img" src="data/soccer-da-0.png" alt="soccer-2" width="500px" />&nbsp;</td>
  <td><p>Dept. Automation Men's Soccer, 2013</p>
  </td></tr></table> -->
  <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-0.jpg" alt="soccer-0" width="500px" />&nbsp;</td>
  <td><p>High school friends in THU-PKU Derby, 2014 </p>
  </td></tr></table>
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-02.JPG" alt="soccer-02" width="500px" />&nbsp;</td>
  <td><p>Best class soccer team at Tsinghua, 2014 </p>
  </td></tr></table> -->
  <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-01.JPG" alt="soccer-01" width="500px" />&nbsp;</td>
  <td><p>Champion at Tsinghua Futsal Tournament, 2014 </p>
  </td></tr></table>
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-3.jpg" alt="soccer-3" width="500px" />&nbsp;</td>
  <td><p>Classmates in the soccer team, 2015</p>
  </td></tr></table> -->
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-4.png" alt="soccer-4" width="500px" />&nbsp;</td>
  <td><p>The 3rd place at Tsinghua Futsal Tournament, 2015</p>
  </td></tr></table> -->
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-9.jpg" alt="soccer-9" width="500px" />&nbsp;</td>
  <td><p>Coaching Dept. Automation Women's Soccer, 2015</p>
  </td></tr></table> -->
  <table class="imgtable"><tr><td>
    <img class="misc-img" src="data/soccer-13.png" alt="soccer-1" width="500px" />&nbsp;</td>
    <td><p>Champion at Automation Tournament, 2016 </p>
    </td></tr></table>
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-5.jpg" alt="soccer-5" width="500px" />&nbsp;</td>
  <td><p>Tsinghua Men's Soccer Team, 2016</p>
  </td></tr></table> -->
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-6.jpg" alt="soccer-6" width="500px" />&nbsp;</td>
  <td><p>Coaching Tsinghua Women's Soccer, 2016</p>
  </td></tr></table> -->
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-1.png" alt="soccer-1" width="500px" />&nbsp;</td>
  <td><p>Champion at Automation Tournament, 2017 </p>
  </td></tr></table> -->
  <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-7.jpg" alt="soccer-7" width="500px" />&nbsp;</td>
  <td><p>Champion at Chinese Alumni League, 2017</p>
  </td></tr></table>
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-8.jpg" alt="soccer-8" width="500px" />&nbsp;</td>
  <td><p>The 2nd place at Triton World Cup, 2017</p>
  </td></tr></table> -->
  <!-- <table class="imgtable"><tr><td>
    <img class="misc-img" src="data/soccer-12.jpg" alt="soccer-12" width="500px" />&nbsp;</td>
    <td><p>NJ Star Soccer Team, Maryland, 2018</p>
    </td></tr></table> -->
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-10.jpg" alt="soccer-9" width="500px" />&nbsp;</td>
  <td><p>Tsinghua Veteran Bay Area Soccer Team, 2019</p>
  </td></tr></table> -->
  <table class="imgtable"><tr><td>
  <img class="misc-img"  src="data/soccer-10-.jpg" alt="soccer-10" width="500px" />&nbsp;</td>
  <td><p>Champion at SV Alumni Soccer Tournament, 2019</p>
  </td></tr></table>
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/soccer-11.jpg" alt="soccer-11" width="500px" />&nbsp;</td>
  <td><p>Calblue Soccer Team, 2019</p>
  </td></tr></table> -->
  </div>

  <h2 class="collapsible" id="running_anchor">Running (click to see more)</h2>
  <div class="content">
  <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/run-3.jpg" alt="running-4" width="500px" />&nbsp;</td>
  <td><p>High school record, 2012 (3000m race)</p>
  </td></tr></table>
  <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/run-4.jpg" alt="running-3" width="500px" />&nbsp;</td>
  <td><p>Unlimited relay race champion at BUAA, 2014 </p>
  </td></tr></table>
  <!-- <table class="imgtable"><tr><td>
    <img class="misc-img" src="data/run-ma.jpg" alt="running-ma" width="500px" />&nbsp;</td>
    <td><p>Dept. Automation, Champion of the 57th Tsinghua Sports Meeting, 2014</p>
    </td></tr></table> -->
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/run-6.jpg" alt="running-6" width="500px" />&nbsp;</td>
  <td><p>Best 4*800m race teams, Tsinghua Sports Meeting, 2014</p>
  </td></tr></table> -->
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/run-7.jpg" alt="running-7" width="500px" />&nbsp;</td>
  <td><p>10*1000m race champion, Tsinghua Sports Meeting, 2015</p>
  </td></tr></table> -->
  <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/run-2.png" alt="running-2" width="500px" />&nbsp;</td>
  <td><p>1500m race champion, Tsinghua Sports Meeting, 2015</p>
  </td></tr></table>
  <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/run-1.jpg" alt="running-1" width="500px" />&nbsp;</td>
  <td><p>4*800m race champion, Tsinghua Sports Meeting, 2015</p>
  </td></tr></table>
  <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/run-5.jpg" alt="running-5" width="500px" />&nbsp;</td>
  <td><p>4*400m race champion, Tsinghua Sports Meeting, 2016</p>
  </td></tr></table>
</div>
  <!-- <table class="imgtable"><tr><td>
    <img class="misc-img" src="data/run-11.jpg" alt="running-10" width="500px" />&nbsp;</td>
    <td><p>5000m 2nd place, 17th Northern California Chinese Culture Federation Sports Meeting, 2019</p>
    </td></tr></table> -->
  <!-- <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/run-9.jpg" alt="running-9" width="500px" />&nbsp;</td>
  <td><p>5000m Champion in Tsinghua Alumni Athletic Meeting (TAAM), 2019</p>
  </td></tr></table>
  <table class="imgtable"><tr><td>
  <img class="misc-img" src="data/run-10.jpg" alt="running-10" width="500px" />&nbsp;</td>
  <td><p>Dept. Automation won the Champion in the 1st TAAM, 2019</p>
  </td></tr></table> -->



  <footer> <!-- 本站所有网页的统一页脚 -->
    <!-- Statcounter code for My homepage https://mengyuest.github.io/ on Google Sites (new) -->
<script type="text/javascript">
  var sc_project=11797803;
  var sc_invisible=0;
  var sc_security="54080103";
  var sc_text=2;
  var scJsHost = "https://";
  document.write("浏览量: <sc"+"ript type='text/javascript' src='" +
  scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script>
  <noscript><div class="statcounter"><a title="hit counter"
  href="https://statcounter.com/" target="_blank"><img
  class="statcounter"
  src="https://c.statcounter.com/11797803/0/54080103/0/"
  alt="hit counter"></a></div></noscript>
  <!-- End of Statcounter Code -->
  </footer>

  <script>
    var coll = document.getElementsByClassName("collapsible");
    console.log(coll.length);
    var i;
  
    for (i = 0; i < coll.length; i++) {
      // coll[i].addEventListener("click", function() {
      //   this.classList.toggle("active");
      //   var content = this.nextElementSibling;
      //   if (content.style.display === "block") {
      //     content.style.display = "none";
      //   } else {
      //     content.style.display = "block";
      //   }
      // });

      coll[i].onclick = function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
          content.style.display = "none";
          this.textContent = this.textContent.split(" ")[0] + " (click to see more)";
        } else {
          content.style.display = "block";
          this.textContent = this.textContent.split(" ")[0] + " (click to collapse)";
        }
      };
    }
  </script>

  <script>
    function collapseFunction(id) {
      var coll = document.getElementById(id);
      coll.classList.toggle("active");
      var content = coll.nextElementSibling;
      content.style.display = "block";
      coll.textContent = coll.textContent.split(" ")[0] + " (click to collapse)";
    }
  </script>

</body>
</html>
